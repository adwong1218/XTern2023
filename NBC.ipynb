{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "689aaaaa-b77a-4f74-8d89-b3192c2eed86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b0fefa26-3782-4e3a-acf3-67ca5a9eb999",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Data into dataframe\n",
    "df = pd.read_csv(\"~/Xtern2023/XTern 2024 Artificial Intelegence Data Set - Xtern_TrainData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8daf4ad0-fe9e-4ba9-a895-c8db7bdaaf0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      (xi, yj, column)  P(xi | yj)\n",
      "0                 (Year 2, Fried Catfish Basket, Year)    0.808163\n",
      "1                      (Year 2, Sugar Cream Pie, Year)    0.107422\n",
      "2                   (Year 2, Indiana Pork Chili, Year)    0.839216\n",
      "3    (Year 2, Indiana Corn on the Cob (brushed with...    0.076768\n",
      "4    (Year 2, Indiana Buffalo Chicken Tacos (3 taco...    0.211694\n",
      "..                                                 ...         ...\n",
      "435                      (8, Sweet Potato Fries, Time)    0.000000\n",
      "436  (8, Ultimate Grilled Cheese Sandwich (with bac...    0.000000\n",
      "437        (8, Breaded Pork Tenderloin Sandwich, Time)    0.012146\n",
      "438                  (8, Cornbread Hush Puppies, Time)    0.001961\n",
      "439        (8, Hoosier BBQ Pulled Pork Sandwich, Time)    0.000000\n",
      "\n",
      "[440 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate P(xi | yj) for each xi in X and yj in y\n",
    "conditional_probabilities = {}\n",
    "\n",
    "# Loop through each column (feature) except the 'Play Golf' column\n",
    "for column in df.columns[:-1]:\n",
    "    # Calculate conditional probabilities P(xi | yj) for each xi and yj\n",
    "    for xi in df[column].unique():\n",
    "        for yj in df['Order'].unique():\n",
    "            p_xi_given_yj = len(df[(df[column] == xi) & (df['Order'] == yj)]) / len(df[df['Order'] == yj])\n",
    "            conditional_probabilities[(xi, yj, column)] = p_xi_given_yj\n",
    "\n",
    "# Display the conditional probabilities table\n",
    "conditional_probabilities_df = pd.DataFrame(list(conditional_probabilities.items()), columns=['(xi, yj, column)', 'P(xi | yj)'])\n",
    "\n",
    "print(conditional_probabilities_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ac3fe8c3-f955-444a-a8b3-ab84f61fdcd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      (xi, yj, column)  P(xi | yj)\n",
      "13   (Year 3, Indiana Corn on the Cob (brushed with...    0.923232\n",
      "18              (Year 3, Cornbread Hush Puppies, Year)    0.894118\n",
      "11                     (Year 3, Sugar Cream Pie, Year)    0.892578\n",
      "19    (Year 3, Hoosier BBQ Pulled Pork Sandwich, Year)    0.852697\n",
      "2                   (Year 2, Indiana Pork Chili, Year)    0.839216\n",
      "..                                                 ...         ...\n",
      "322  (Indiana University Bloomington, Indiana Pork ...    0.000000\n",
      "323  (Indiana University Bloomington, Indiana Corn ...    0.000000\n",
      "324  (Indiana University Bloomington, Indiana Buffa...    0.000000\n",
      "325  (Indiana University Bloomington, Sweet Potato ...    0.000000\n",
      "439        (8, Hoosier BBQ Pulled Pork Sandwich, Time)    0.000000\n",
      "\n",
      "[440 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Sorting the Conditional Probabilities Table by P(xi | yj)\n",
    "conditional_probabilities_df = conditional_probabilities_df.sort_values('P(xi | yj)', ascending=False)\n",
    "\n",
    "print(conditional_probabilities_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "61347425-eaae-42df-b57f-cdc56572c39a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converting Columns Into Integers\n",
    "\n",
    "# Creating instance of label converter\n",
    "lab = LabelEncoder()\n",
    "\n",
    "# Encoding labels for year\n",
    "df_encoded = df\n",
    "df_encoded['Year'] = lab.fit_transform(df_encoded['Year'])\n",
    "df_encoded['Major'] = lab.fit_transform(df_encoded['Major'])\n",
    "df_encoded['University'] = lab.fit_transform(df_encoded['University'])\n",
    "df_encoded['Order'] = lab.fit_transform(df_encoded['Order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "474566f3-5d87-4b48-8faf-373b4009d7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breaking up our dataframe into x and y\n",
    "x = df_encoded.drop(['Order'], axis = 1)\n",
    "y = df_encoded.Order.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e20899f1-9c66-446d-8cad-fe629e430b89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splitting the Dataset into Training and Testing Sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3f8b3d16-e640-44d2-ade7-ab0f78d9b498",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-30 {color: black;}#sk-container-id-30 pre{padding: 0;}#sk-container-id-30 div.sk-toggleable {background-color: white;}#sk-container-id-30 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-30 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-30 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-30 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-30 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-30 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-30 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-30 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-30 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-30 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-30 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-30 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-30 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-30 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-30 div.sk-item {position: relative;z-index: 1;}#sk-container-id-30 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-30 div.sk-item::before, #sk-container-id-30 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-30 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-30 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-30 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-30 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-30 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-30 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-30 div.sk-label-container {text-align: center;}#sk-container-id-30 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-30 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-30\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" checked><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing Gaussian Naive Bayes\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2da08cba-9e08-48aa-acdb-9cb470b56ecd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes score:  0.4686666666666667\n"
     ]
    }
   ],
   "source": [
    "# Result of Gaussian Naive Bayes Model\n",
    "print(\"Gaussian Naive Bayes score: \", gnb.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d615f448-afc5-4a18-b0f4-ab5f901336d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-31 {color: black;}#sk-container-id-31 pre{padding: 0;}#sk-container-id-31 div.sk-toggleable {background-color: white;}#sk-container-id-31 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-31 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-31 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-31 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-31 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-31 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-31 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-31 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-31 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-31 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-31 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-31 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-31 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-31 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-31 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-31 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-31 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-31 div.sk-item {position: relative;z-index: 1;}#sk-container-id-31 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-31 div.sk-item::before, #sk-container-id-31 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-31 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-31 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-31 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-31 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-31 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-31 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-31 div.sk-label-container {text-align: center;}#sk-container-id-31 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-31 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-31\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CategoricalNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" checked><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CategoricalNB</label><div class=\"sk-toggleable__content\"><pre>CategoricalNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CategoricalNB()"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Improvements\n",
    "# GaussianNB is more for continuous numbers, but we are working with categories. Let's try CategoricalNB\n",
    "cnb = CategoricalNB()\n",
    "cnb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5bff9f06-cfcc-4cb2-a813-feed050a2bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Naive Bayes score:  0.604\n",
      "0.486\n",
      "0.612\n",
      "4\n",
      "0.4646666666666667\n",
      "0.5973333333333334\n",
      "5\n",
      "0.482\n",
      "0.598\n",
      "6\n",
      "0.4653333333333333\n",
      "0.5953333333333334\n",
      "7\n",
      "0.4786666666666667\n",
      "0.586\n",
      "8\n",
      "0.48533333333333334\n",
      "0.5986666666666667\n",
      "9\n",
      "0.47933333333333333\n",
      "0.6126666666666667\n",
      "10\n",
      "0.5006666666666667\n",
      "0.6153333333333333\n",
      "11\n",
      "0.486\n",
      "0.606\n",
      "12\n",
      "0.4646666666666667\n",
      "0.5866666666666667\n",
      "13\n",
      "0.48933333333333334\n",
      "0.616\n",
      "14\n",
      "0.49066666666666664\n",
      "0.614\n",
      "15\n",
      "0.496\n",
      "0.6126666666666667\n",
      "16\n",
      "0.488\n",
      "0.5973333333333334\n",
      "17\n",
      "0.47533333333333333\n",
      "0.602\n",
      "18\n",
      "0.45466666666666666\n",
      "0.5653333333333334\n",
      "19\n",
      "0.49733333333333335\n",
      "0.5933333333333334\n",
      "20\n",
      "0.47533333333333333\n",
      "0.5966666666666667\n",
      "21\n",
      "0.4693333333333333\n",
      "0.598\n",
      "22\n",
      "0.4706666666666667\n",
      "0.6026666666666667\n",
      "23\n",
      "0.4706666666666667\n",
      "0.5946666666666667\n",
      "24\n",
      "0.4866666666666667\n",
      "0.6\n",
      "25\n",
      "0.4686666666666667\n",
      "0.604\n",
      "26\n",
      "0.464\n",
      "0.6073333333333333\n",
      "27\n",
      "0.4886666666666667\n",
      "0.6106666666666667\n",
      "28\n",
      "0.4686666666666667\n",
      "0.5853333333333334\n",
      "29\n",
      "0.4846666666666667\n",
      "0.6013333333333334\n",
      "30\n",
      "0.47\n",
      "0.606\n",
      "31\n",
      "0.48533333333333334\n",
      "0.6193333333333333\n",
      "32\n",
      "0.484\n",
      "0.5833333333333334\n",
      "33\n",
      "0.49533333333333335\n",
      "0.6126666666666667\n",
      "34\n",
      "0.46066666666666667\n",
      "0.598\n",
      "35\n",
      "0.494\n",
      "0.6266666666666667\n",
      "36\n",
      "0.4726666666666667\n",
      "0.59\n",
      "37\n",
      "0.482\n",
      "0.608\n",
      "38\n",
      "0.492\n",
      "0.608\n",
      "39\n",
      "0.47333333333333333\n",
      "0.5893333333333334\n",
      "40\n",
      "0.482\n",
      "0.6013333333333334\n",
      "41\n",
      "0.49266666666666664\n",
      "0.596\n",
      "42\n",
      "0.484\n",
      "0.6053333333333333\n",
      "43\n",
      "0.48\n",
      "0.6033333333333334\n",
      "44\n",
      "0.4826666666666667\n",
      "0.6053333333333333\n",
      "45\n",
      "0.492\n",
      "0.6146666666666667\n",
      "46\n",
      "0.49666666666666665\n",
      "0.6206666666666667\n",
      "47\n",
      "0.4573333333333333\n",
      "0.5933333333333334\n",
      "48\n",
      "0.4713333333333333\n",
      "0.598\n",
      "49\n",
      "0.486\n",
      "0.592\n",
      "50\n",
      "0.4866666666666667\n",
      "0.5993333333333334\n",
      "51\n",
      "0.484\n",
      "0.6046666666666667\n",
      "52\n",
      "0.5046666666666667\n",
      "0.6153333333333333\n",
      "53\n",
      "0.49266666666666664\n",
      "0.596\n",
      "54\n",
      "0.474\n",
      "0.5906666666666667\n",
      "55\n",
      "0.49466666666666664\n",
      "0.6093333333333333\n",
      "56\n",
      "0.472\n",
      "0.5793333333333334\n",
      "57\n",
      "0.492\n",
      "0.596\n",
      "58\n",
      "0.502\n",
      "0.6053333333333333\n",
      "59\n",
      "0.4886666666666667\n",
      "0.5913333333333334\n",
      "60\n",
      "0.4746666666666667\n",
      "0.5886666666666667\n",
      "61\n",
      "0.488\n",
      "0.6113333333333333\n",
      "62\n",
      "0.5173333333333333\n",
      "0.604\n",
      "63\n",
      "0.492\n",
      "0.5873333333333334\n",
      "64\n",
      "0.4726666666666667\n",
      "0.5933333333333334\n",
      "65\n",
      "0.48533333333333334\n",
      "0.6006666666666667\n",
      "66\n",
      "0.46066666666666667\n",
      "0.572\n",
      "67\n",
      "0.48533333333333334\n",
      "0.6\n",
      "68\n",
      "0.45066666666666666\n",
      "0.5766666666666667\n",
      "69\n",
      "0.48533333333333334\n",
      "0.594\n",
      "70\n",
      "0.47533333333333333\n",
      "0.594\n",
      "71\n",
      "0.486\n",
      "0.6033333333333334\n",
      "72\n",
      "0.452\n",
      "0.59\n",
      "73\n",
      "0.4766666666666667\n",
      "0.5853333333333334\n",
      "74\n",
      "0.47933333333333333\n",
      "0.604\n",
      "75\n",
      "0.49933333333333335\n",
      "0.6153333333333333\n",
      "76\n",
      "0.4673333333333333\n",
      "0.576\n",
      "77\n",
      "0.4726666666666667\n",
      "0.5973333333333334\n",
      "78\n",
      "0.496\n",
      "0.6126666666666667\n",
      "79\n",
      "0.452\n",
      "0.5893333333333334\n",
      "80\n",
      "0.48733333333333334\n",
      "0.5866666666666667\n",
      "81\n",
      "0.4653333333333333\n",
      "0.62\n",
      "82\n",
      "0.4886666666666667\n",
      "0.6046666666666667\n",
      "83\n",
      "0.492\n",
      "0.5966666666666667\n",
      "84\n",
      "0.4846666666666667\n",
      "0.596\n",
      "85\n",
      "0.4846666666666667\n",
      "0.594\n",
      "86\n",
      "0.48133333333333334\n",
      "0.598\n",
      "87\n",
      "0.5006666666666667\n",
      "0.6\n",
      "88\n",
      "0.474\n",
      "0.5946666666666667\n",
      "89\n",
      "0.47533333333333333\n",
      "0.6233333333333333\n",
      "90\n",
      "0.48\n",
      "0.614\n",
      "91\n",
      "0.45666666666666667\n",
      "0.5766666666666667\n",
      "92\n",
      "0.472\n",
      "0.5913333333333334\n",
      "93\n",
      "0.48133333333333334\n",
      "0.6086666666666667\n",
      "94\n",
      "0.4666666666666667\n",
      "0.6\n",
      "95\n",
      "0.5073333333333333\n",
      "0.6133333333333333\n",
      "96\n",
      "0.49\n",
      "0.6253333333333333\n",
      "97\n",
      "0.48\n",
      "0.5946666666666667\n",
      "98\n",
      "0.46\n",
      "0.5986666666666667\n",
      "99\n",
      "0.5073333333333333\n",
      "0.6126666666666667\n",
      "100\n",
      "0.4886666666666667\n",
      "0.616\n",
      "101\n",
      "0.4653333333333333\n",
      "0.6026666666666667\n",
      "102\n",
      "0.48333333333333334\n",
      "0.604\n",
      "103\n",
      "0.486\n",
      "0.602\n",
      "104\n",
      "0.4686666666666667\n",
      "0.5893333333333334\n",
      "105\n",
      "0.482\n",
      "0.6086666666666667\n",
      "106\n",
      "0.4786666666666667\n",
      "0.5933333333333334\n",
      "107\n",
      "0.47933333333333333\n",
      "0.584\n",
      "108\n",
      "0.476\n",
      "0.5813333333333334\n",
      "109\n",
      "0.49866666666666665\n",
      "0.6206666666666667\n",
      "110\n",
      "0.462\n",
      "0.6006666666666667\n",
      "111\n",
      "0.49266666666666664\n",
      "0.5993333333333334\n",
      "112\n",
      "0.4766666666666667\n",
      "0.5993333333333334\n",
      "113\n",
      "0.4746666666666667\n",
      "0.62\n",
      "114\n",
      "0.47933333333333333\n",
      "0.612\n",
      "115\n",
      "0.482\n",
      "0.602\n",
      "116\n",
      "0.49066666666666664\n",
      "0.602\n",
      "117\n",
      "0.5013333333333333\n",
      "0.6106666666666667\n",
      "118\n",
      "0.4886666666666667\n",
      "0.5986666666666667\n",
      "119\n",
      "0.492\n",
      "0.606\n",
      "120\n",
      "0.476\n",
      "0.5826666666666667\n",
      "121\n",
      "0.45666666666666667\n",
      "0.5913333333333334\n",
      "122\n",
      "0.4693333333333333\n",
      "0.5813333333333334\n",
      "123\n",
      "0.4886666666666667\n",
      "0.5886666666666667\n",
      "124\n",
      "0.49333333333333335\n",
      "0.602\n",
      "125\n",
      "0.4886666666666667\n",
      "0.5833333333333334\n",
      "126\n",
      "0.486\n",
      "0.5986666666666667\n",
      "127\n",
      "0.4706666666666667\n",
      "0.6\n",
      "128\n",
      "0.508\n",
      "0.616\n",
      "129\n",
      "0.4746666666666667\n",
      "0.5906666666666667\n",
      "130\n",
      "0.478\n",
      "0.5866666666666667\n",
      "131\n",
      "0.482\n",
      "0.5846666666666667\n",
      "132\n",
      "0.49533333333333335\n",
      "0.6153333333333333\n",
      "133\n",
      "0.4786666666666667\n",
      "0.592\n",
      "134\n",
      "0.478\n",
      "0.592\n",
      "135\n",
      "0.47533333333333333\n",
      "0.6126666666666667\n",
      "136\n",
      "0.49333333333333335\n",
      "0.5806666666666667\n",
      "137\n",
      "0.49933333333333335\n",
      "0.6186666666666667\n",
      "138\n",
      "0.4786666666666667\n",
      "0.5846666666666667\n",
      "139\n",
      "0.48933333333333334\n",
      "0.5893333333333334\n",
      "140\n",
      "0.4713333333333333\n",
      "0.588\n",
      "141\n",
      "0.47533333333333333\n",
      "0.5886666666666667\n",
      "142\n",
      "0.464\n",
      "0.578\n",
      "143\n",
      "0.4826666666666667\n",
      "0.612\n",
      "144\n",
      "0.4726666666666667\n",
      "0.598\n",
      "145\n",
      "0.488\n",
      "0.602\n",
      "146\n",
      "0.4826666666666667\n",
      "0.5906666666666667\n",
      "147\n",
      "0.49533333333333335\n",
      "0.6053333333333333\n",
      "148\n",
      "0.49066666666666664\n",
      "0.6033333333333334\n",
      "149\n",
      "0.464\n",
      "0.5906666666666667\n",
      "150\n",
      "0.48333333333333334\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 1 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[109], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m cnb\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(gnb\u001b[38;5;241m.\u001b[39mscore(x_test, y_test))\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28mprint\u001b[39m(cnb\u001b[38;5;241m.\u001b[39mscore(x_test, y_test))\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(i)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:705\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[38;5;124;03m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001b[39;00m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m--> 705\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(X), sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:102\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    100\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    101\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X(X)\n\u001b[1;32m--> 102\u001b[0m jll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_joint_log_likelihood(X)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(jll, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:1526\u001b[0m, in \u001b[0;36mCategoricalNB._joint_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_):\n\u001b[0;32m   1525\u001b[0m     indices \u001b[38;5;241m=\u001b[39m X[:, i]\n\u001b[1;32m-> 1526\u001b[0m     jll \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_log_prob_[i][:, indices]\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m   1527\u001b[0m total_ll \u001b[38;5;241m=\u001b[39m jll \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_log_prior_\n\u001b[0;32m   1528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_ll\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for axis 1 with size 3"
     ]
    }
   ],
   "source": [
    "# Result of Categorical Naive Bayes Model\n",
    "print(\"Categorical Naive Bayes score: \", cnb.score(x_test, y_test))\n",
    "\n",
    "maxScore = 0\n",
    "maxIndex = 0\n",
    "for i in range(4, 1000):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = i)\n",
    "    \n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(x_train, y_train)\n",
    "    \n",
    "    cnb = CategoricalNB()\n",
    "    cnb.fit(x_train, y_train)\n",
    "    \n",
    "    print(gnb.score(x_test, y_test))\n",
    "    print(cnb.score(x_test, y_test))\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2fe344c-1cb0-4d7f-af30-098a234ef64c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is pretty terrible, so let's try this using one hot encoding!\n",
    "# Import Data into dataframe\n",
    "df = pd.read_csv(\"~/Xtern2023/XTern 2024 Artificial Intelegence Data Set - Xtern_TrainData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51f3518f-687c-4121-b43f-d00092752365",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Order</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time  Order    0    1    2    3    4    5    6    7  ...   10   11   12  \\\n",
       "0    12      2  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1    14      7  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2    12      6  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3    11      2  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4    12      5  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "    13   14   15   16   17   18   19  \n",
       "0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing labels from objects to floats using One Hot Encoding\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Encoding University, Year and Major\n",
    "encoded_uni_df = pd.DataFrame(encoder.fit_transform(df[['University']]).toarray())\n",
    "encoded_year_df = pd.DataFrame(encoder.fit_transform(df[['Year']]).toarray())\n",
    "encoded_major_df = pd.DataFrame(encoder.fit_transform(df[['Major']]).toarray())\n",
    "\n",
    "# Drop original Year and Major columns\n",
    "one_hot_df = df.drop(['Year', 'Major', 'University'], axis=1)\n",
    "\n",
    "# Adding new columns back into df\n",
    "one_hot_df = pd.concat([one_hot_df, encoded_uni_df, encoded_year_df, encoded_major_df], axis=1)\n",
    "\n",
    "# Creating instance of label converter\n",
    "lab = LabelEncoder()\n",
    "one_hot_df['Order'] = lab.fit_transform(one_hot_df['Order'])\n",
    "\n",
    "# Making Sure All Column Names are Strings\n",
    "one_hot_df.columns = one_hot_df.columns.astype(str)\n",
    "\n",
    "one_hot_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "852de7ac-582e-44d7-a787-b51cf2d8306d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Time    0    1    2    3    4    5    6    7    8  ...   10   11   12  \\\n",
      "0       12  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "1       14  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "2       12  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "3       11  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "4       12  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "4995    11  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
      "4996    12  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "4997    13  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "4998    15  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "4999    15  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
      "\n",
      "       13   14   15   16   17   18   19  \n",
      "0     0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
      "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...   ...  ...  ...  ...  ...  ...  ...  \n",
      "4995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[5000 rows x 35 columns]\n",
      "0       2\n",
      "1       7\n",
      "2       6\n",
      "3       2\n",
      "4       5\n",
      "       ..\n",
      "4995    0\n",
      "4996    9\n",
      "4997    7\n",
      "4998    7\n",
      "4999    0\n",
      "Name: Order, Length: 5000, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# Performing Naive Bayes Again, but with our new One Hot Encoded DataFrame!\n",
    "\n",
    "# Breaking up our dataframe into x and y\n",
    "x = one_hot_df.drop(['Order'], axis = 1)\n",
    "y = one_hot_df['Order']\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1547ca1-f3a7-41ba-8094-92fac8582327",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splitting the Dataset into Training and Testing Sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef3af6a4-a2fc-4819-9d60-a7eba3aa19f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing Gaussian Naive Bayes\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3f53165-88f0-4a9f-824f-a4b59b72f464",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes score using One-Hot Encoding:  0.24333333333333335\n"
     ]
    }
   ],
   "source": [
    "# Result of Naive Bayes Model\n",
    "print(\"Naive Bayes score using One-Hot Encoding: \", gnb.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e08fc50-f215-4af1-a52b-1654d0b6f9ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
